{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize HuBMAP and KPMP datasets for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install pre-requisite libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install anndata pandas seaborn matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: extract obs variables to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports / functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h5ad_obs_to_csv(input_h5ad):\n",
    "    output_csv = input_h5ad.replace('.h5ad', '.obs.csv')\n",
    "    x = anndata.read_h5ad(input_h5ad, backed='r')\n",
    "    x.obs.to_csv(output_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "  'KPMP SC RNAseq': 'kpmp-sc-rnaseq.h5ad',\n",
    "  'KPMP SN RNAseq': 'kpmp-sn-rnaseq.h5ad',\n",
    "  'HuBMAP Left Kidney': 'hubmap-LK-processed.h5ad',\n",
    "  'HuBMAP Right Kidney': 'hubmap-RK-processed.h5ad'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out dataset obs variables to separate csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h5ad in datasets.values():\n",
    "    h5ad_obs_to_csv(h5ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -3 *.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: normalize and combine obs datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports / functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_category(str):\n",
    "    str = str.strip()\n",
    "    if str == \"\" or str == \"unknown\":\n",
    "        return \"Unknown\"\n",
    "    else:\n",
    "        return str\n",
    "\n",
    "def normalized_age(age):\n",
    "    match age.split(\" \")[0]:\n",
    "        case \"first\":\n",
    "            age = 0\n",
    "        case \"second\":\n",
    "            age = 10\n",
    "        case \"third\":\n",
    "            age = 20\n",
    "        case \"fourth\":\n",
    "            age = 30\n",
    "        case \"fifth\":\n",
    "            age = 40\n",
    "        case \"sixth\":\n",
    "            age = 50\n",
    "        case \"seventh\":\n",
    "            age = 60\n",
    "        case \"eighth\":\n",
    "            age = 70\n",
    "        case \"nineth\":\n",
    "            age = 80\n",
    "        case \"tenth\":\n",
    "            age = 90\n",
    "    age = str(age)\n",
    "    if age != \"\" and age[0].isdigit():\n",
    "        return f\"{age[0]}0-{age[0]}9\"\n",
    "    else:\n",
    "        return normalize_category(age)\n",
    "\n",
    "def normalize_race(race):\n",
    "    if race == \"African American\":\n",
    "        return \"Black or African American\"\n",
    "    else:\n",
    "        return normalize_category(race)\n",
    "\n",
    "def normalize_hubmap_row(row, collection):\n",
    "    normalized_row = {\n",
    "        \"consortium\": \"HuBMAP\",\n",
    "        \"collection\": collection,\n",
    "        \"dataset_id\": row[\"uuid\"],\n",
    "        \"cell_id\": row[\"cell_id\"],\n",
    "        \"as_id\": \"UBERON:0002113\",\n",
    "        \"cl_id\": row[\"predicted_CLID\"],\n",
    "        \"cl_label\": row[\"predicted_label\"],\n",
    "        \"gene_count\": int(row[\"n_genes\"]),\n",
    "        \"age\": normalized_age(row[\"age\"]),\n",
    "        \"sex\": normalize_category(row[\"sex\"].title()),\n",
    "        \"race\": normalize_race(row[\"race\"]),\n",
    "        \"disease\": \"normal\"\n",
    "    }\n",
    "    return normalized_row\n",
    "\n",
    "def normalize_kpmp_row(row, collection):\n",
    "    normalized_row = {\n",
    "        \"consortium\": \"KPMP\",\n",
    "        \"collection\": collection,\n",
    "        \"dataset_id\": row.get(\"LibraryID\", row.get(\"library_id\", \"Unknown\")),\n",
    "        \"cell_id\": row[\"\"],\n",
    "        \"as_id\": row[\"tissue_ontology_term_id\"],\n",
    "        \"cl_id\": row[\"cell_type_ontology_term_id\"],\n",
    "        \"cl_label\": row[\"cell_type\"],\n",
    "        \"gene_count\": int(float(row[\"nCount_RNA\"])),\n",
    "        \"age\": normalized_age(row[\"Age_binned\"]),\n",
    "        \"sex\": normalize_category(row[\"sex\"].title()),\n",
    "        \"race\": normalize_race(row[\"self_reported_ethnicity\"]),\n",
    "        \"disease\": normalize_category(row[\"disease\"])\n",
    "    }\n",
    "    return normalized_row\n",
    "\n",
    "fields = [\"consortium\", \"collection\", \"dataset_id\", \"cell_id\", \"as_id\", \"cl_id\", \"cl_label\", \"gene_count\", \"age\", \"sex\", \"race\", \"disease\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in obs data and write out a normalized csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import gzip\n",
    "with gzip.open(\"all-normalized-obs.csv.gz\", 'wt', compresslevel=9, newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fields)\n",
    "    writer.writeheader()\n",
    "    for (collection, h5ad) in datasets.items():\n",
    "        obs_csv = h5ad.replace(\".h5ad\", \".obs.csv\")\n",
    "        with open(obs_csv, newline='') as obs_csvfile:\n",
    "            reader = csv.DictReader(obs_csvfile)\n",
    "            for row in reader:\n",
    "                if h5ad.startswith(\"hubmap-\"):\n",
    "                    normalized_row = normalize_hubmap_row(row, collection)\n",
    "                else:\n",
    "                    normalized_row = normalize_kpmp_row(row, collection)\n",
    "                writer.writerow(normalized_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zcat all-normalized-obs.csv.gz | head -3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: show basic results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports / functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display unique values in normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"all-normalized-obs.csv.gz\")\n",
    "\n",
    "# Create a dictionary to store unique values for each column\n",
    "unique_values = {column: df[column].unique() for column in df.columns}\n",
    "\n",
    "# Print unique values for each column\n",
    "for column, values in unique_values.items():\n",
    "    if len(values) < 100:\n",
    "        print(f\"\\\"{column}\\\" values ({len(values)}): {', '.join(values)}\")\n",
    "    else:\n",
    "        print(f\"\\\"{column}\\\" values ({len(values)}): {', '.join(map(str, values))[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize distributions of metadata by cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the aesthetic style of the plots\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "def plot_distribution(x, column):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.xticks(rotation=90, fontsize=8)\n",
    "    sorted_values = sorted(unique_values[column], key=lambda v: v.lower())\n",
    "    sns.countplot(x=column, data=x, order=sorted_values)\n",
    "    plt.gcf().subplots_adjust(bottom=0.4)\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('cell count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the distribution of each column\n",
    "for column in df.columns:\n",
    "    if len(unique_values[column]) < 100:\n",
    "        plot_distribution(df, column)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
